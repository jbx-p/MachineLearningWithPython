{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d274932",
      "metadata": {
        "id": "2d274932"
      },
      "source": [
        "<a \n",
        " href=\"https://colab.research.google.com/github/LearnPythonWithRune/MachineLearningWithPython/blob/main/colab/final/14 - Project - Word2Vec.ipynb\"\n",
        " target=\"_parent\">\n",
        "<img \n",
        " src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b13b1e",
      "metadata": {
        "id": "56b13b1e"
      },
      "source": [
        "# Project: Create a Word2Vec Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b981a3",
      "metadata": {
        "id": "49b981a3"
      },
      "source": [
        "### Step 1: Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f2f684a5",
      "metadata": {
        "id": "f2f684a5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "from os import system\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c9efc384",
      "metadata": {
        "id": "c9efc384"
      },
      "outputs": [],
      "source": [
        "# Create local directories in Google Colab\n",
        "!mkdir -p files/holmes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "00e93184",
      "metadata": {
        "id": "00e93184"
      },
      "outputs": [],
      "source": [
        "# This part, only for colabs, in order to have all the fullpath name in the list \"holmes_files\"\n",
        "\n",
        "REMOTE_DIRECTORY = \"https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/files/holmes/\"\n",
        "\n",
        "FILES = [\"bachelor.txt\", \"clerk.txt\", \"face.txt \", \"problem.txt\", \"twisted.txt\", \"blaze.txt\", \"copper.txt\" , \"gloria_scott.txt\", \"ritual.txt\", \"bohemia.txt\", \"coronet.txt\", \"interpreter.txt\", \"speckled.txt\", \"boscombe.txt\", \"crooked.txt \", \"league.txt\", \"squires.txt\", \"carbuncle.txt\", \"engineer.txt\", \"atient.txt\", \"treaty.txt\"]\n",
        "\n",
        "holmes_files = []\n",
        "for filename in FILES:\n",
        "    full_name = REMOTE_DIRECTORY + filename\n",
        "    system(\"curl -o files/holmes/\"+filename+\" \"+full_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98c3250",
      "metadata": {
        "id": "a98c3250"
      },
      "source": [
        "### Step 2: Download stopwords\n",
        "- Execute the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dbc59a32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc59a32",
        "outputId": "02972312-5e4b-4219-e042-55fa243340f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9012c520",
      "metadata": {
        "id": "9012c520"
      },
      "source": [
        "### Step 3: Read content and sentinize\n",
        "- Initialize an empty list called **all_sentences**\n",
        "- For each filename in **'files/holmes'**:\n",
        "    - HINT: Use **os.listdir(...)** ([docs](https://docs.python.org/3/library/os.html#os.listdir))\n",
        "- Open the file and read the content and convert to lowercase and apply **nltk.sent_tokenize** on content.\n",
        "    - Use **lower()** on content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "12d17b83",
      "metadata": {
        "id": "12d17b83"
      },
      "outputs": [],
      "source": [
        "all_sentences = []\n",
        "\n",
        "for filename in os.listdir('files/holmes'):\n",
        "    with open(f'files/holmes/{filename}') as f:\n",
        "        content = f.read()\n",
        "        all_sentences += nltk.sent_tokenize(content.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31914b8b",
      "metadata": {
        "id": "31914b8b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "64e4362c",
      "metadata": {
        "id": "64e4362c"
      },
      "source": [
        "### Step 4: Tokenize each sentence\n",
        "- Get all words by applying **nltk.word_tokenize** on them and assign the result to **all_words**\n",
        "    - HINT: Use list comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "74bc20df",
      "metadata": {
        "id": "74bc20df"
      },
      "outputs": [],
      "source": [
        "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bb5143be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb5143be",
        "outputId": "09460323-abdb-4eb4-81f3-bab7aa06ebbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'adventure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'blue',\n",
              " 'carbuncle',\n",
              " 'i',\n",
              " 'had',\n",
              " 'called',\n",
              " 'upon']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "all_words[0][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "959014e8",
      "metadata": {
        "id": "959014e8"
      },
      "source": [
        "### Step 5: Remove all stop words\n",
        "- Use **stopwords.words('english')** to filter all the words in **all_words**\n",
        "    - HINT: iterate over the length of **all_words**, for each index use list comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "056ed61a",
      "metadata": {
        "id": "056ed61a"
      },
      "outputs": [],
      "source": [
        "for i in range(len(all_words)):\n",
        "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffef523",
      "metadata": {
        "id": "3ffef523"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40656352",
      "metadata": {
        "id": "40656352"
      },
      "source": [
        "### Step 6: Remove special characters\n",
        "- Iterate over items in **all_words** to remove words with special characters\n",
        "    - HINT: Use **isalpha()** ([doc](https://docs.python.org/3/library/stdtypes.html#str.isalpha))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2e6a0003",
      "metadata": {
        "id": "2e6a0003"
      },
      "outputs": [],
      "source": [
        "for i in range(len(all_words)):\n",
        "    all_words[i] = [w for w in all_words[i] if w.isalpha()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a52d6b5",
      "metadata": {
        "id": "6a52d6b5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b8bca8cf",
      "metadata": {
        "id": "b8bca8cf"
      },
      "source": [
        "### Step 7: Install gensim and python-Levenshtein\n",
        "- Run the following cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8036c213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8036c213",
        "outputId": "34556f45-8aa7-47df-d830-b7654adc95d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aa499e7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa499e7b",
        "outputId": "04ada09f-1e3c-4419-aea6-4913c2d6ae14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.20.9\n",
            "  Downloading Levenshtein-0.20.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.20.9 python-Levenshtein-0.20.9 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e16a94c5",
      "metadata": {
        "id": "e16a94c5"
      },
      "source": [
        "### Step 8: Import another library\n",
        "- Run the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6e7179bf",
      "metadata": {
        "id": "6e7179bf"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dad3d2",
      "metadata": {
        "id": "b6dad3d2"
      },
      "source": [
        "### Step 9: Create a model\n",
        "- Use **Word2Vec** on **all_words**\n",
        "    - Use **min_count=2** : Ignores all words with total frequency lower than this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a5fa076a",
      "metadata": {
        "id": "a5fa076a"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(all_words, min_count=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1940078",
      "metadata": {
        "id": "e1940078"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1da22183",
      "metadata": {
        "id": "1da22183"
      },
      "source": [
        "### Step 10: Find distances\n",
        "- Try to run **model.wv.distance('holmes', 'watson')**\n",
        "- Try to run **model.wv.distance('holmes', 'water')**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "18791254",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18791254",
        "outputId": "0c1e1a9e-2569-4627-fc8f-7450d1076e34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00013363361358642578"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.wv.distance('holmes', 'watson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f285841f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f285841f",
        "outputId": "d12cd048-e455-4527-a641-ee37235676d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00038683414459228516"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.wv.distance('holmes', 'water')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b26dd8c",
      "metadata": {
        "id": "6b26dd8c"
      },
      "source": [
        "### Step 11: Find closests words\n",
        "- Get all the words\n",
        "    - HINT: **words = model.wv.index2entity**\n",
        "- Implement a function **closets_words(word)**\n",
        "    - HINT: **distances = {w: model.wv.distance(word, w) for w in words}**\n",
        "    - HINT: **sorted(distances, key=lambda w: distances[w])[:15]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "90a2702f",
      "metadata": {
        "id": "90a2702f"
      },
      "outputs": [],
      "source": [
        "words = model.wv.index2entity\n",
        "\n",
        "def closets_words(word):\n",
        "    distances = {w: model.wv.distance(word, w) for w in words}\n",
        "    return sorted(distances, key=lambda w: distances[w])[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d196ecab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d196ecab",
        "outputId": "e57bd390-9e7b-470c-c018-f27c05de2d69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['holmes',\n",
              " 'well',\n",
              " 'rather',\n",
              " 'friend',\n",
              " 'round',\n",
              " 'may',\n",
              " 'one',\n",
              " 'man',\n",
              " 'way',\n",
              " 'house',\n",
              " 'might',\n",
              " 'upon',\n",
              " 'little',\n",
              " 'time',\n",
              " 'took']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "closets_words('holmes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c22630",
      "metadata": {
        "id": "b6c22630"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}